---
header-includes: 
  - \thispagestyle{empty}
  - \usepackage{setspace}
  - \setstretch{2}
  - \AtBeginEnvironment{tabular}{\doublespacing}
  - \AtBeginEnvironment{lltable}{\doublespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
  - \usepackage{booktabs}

title             : "NP3"
shorttitle        : "NP3"

author: 
  - name          : "Dion T. Henare"
    affiliation   : "1"
    corresponding : yes
    address       : "Gutenbergstraße 18, 35032 Marburg"
    email         : "dion.henare@uni-marburg.de"
  - name          : "Jan Tunnermann"
    affiliation   : "1"
  - name          : "Ilja Wagner"
    affiliation   : "1"
  - name          : "Alexander C. Schütz"
    affiliation   : "1"
  - name          : "Anna Schuboe"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Philipps-University of Marburg, Germany"

author_note: |
  Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – project number 222641018 – SFB/TRR 135 TP B3

abstract: |
  Abstract goes here

bibliography      : ["NP32019_references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

numbersection     : no
class             : "man"
output            : papaja::apa6_word

---

\raggedbottom

```{r setup, include = FALSE}
set.seed(4609948)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
library(knitr)
opts_chunk$set(echo = FALSE)
library("papaja")
library(tidyr)
library(dplyr)
library(ggplot2)
library(afex)
library(xtable)
library(RColorBrewer)
library(emmeans)
```

# Introduction

A central goal of the field of cognitive science is to understand how the human visual system prioritses relevant stimuli for high level processing while ignoring irrelevant noise. Seminal work in this literature has relied on a broad set of experimental paradigms where participants search for predefined targets amoung a set of irrelevant distractor or filler objects. 

In everyday situations, however, we are often faced with the challlenge of not simply finding a specific target, but optimising our performance in a context where multiple possible targets are present. 

Recent work has started to expand on experimental paradigms in order to incorporate target choice processes. Irons and leber 2015/2016

EEG studies examining selective attention have identified a lateralised ERP component that has p

# Methods

## Participants

## Task 

### Calibration session

### EEG session

Each trial began with a 500ms fixation followed by a search display that was shown for 500ms, and then a fixation display lasting until response (uo to a maximum of 1500ms). The search display consisted of 16 rings, eight rings to the left of fixation and eight rings to the right of fixation. The rings on each side were arranged in two columns of four, and the layout of each column was curved to ensure that rings within a column were equidistant from fixation. In this way, stimuli can be thought of as falling along the imaginary line of either an inner or outer circle around fixation. Each ring contained a rounded rectangle with a gap in the centre of one of the long sides. One of these rectangles was oriented horizontally, one of these rectangles was oriented vertically, and the remaining 14 rectangles were tilted at a 45 degree angle. Participants were required to select either the vertical or horizontal rectangle, and indicate the edge that contained a gap. Responses were made on an ergodex key pad using keys arranged like the arrow keys of a standard computer keyboard. The two target rectangles were always presented on opposite sides of fixation, one left and one right, with the restriction that they would always be the same distance from fixation ie. both targets would be presented on the inner circle of rings, or both on the outer circle. 

Two factors were manipulated in order to affect participant performance. Firstly, the two targets differed with regard to the difficulty of the gap judgement. One rectangle contained a smaller gap size that was calibrated to be reportable on approximately 65% of trials, whereas the other rectangle contained a larger gap size that was calibrated to be reportable on approximately 90% of trials. 

Secondly, possible target locations were highlighted by colouring a portion of the rings either red or blue. Locations of the coloured rings were randomly determined on each trial, however there were always eight coloured rings on screen in total. Therefore, the ratio of red to blue rings varied across trials from 1:7 to 7:1 (with an even distribution of every possible ratio). For each participant, one of the colours highlighted the possible locations of the easy target, and the other colour highlighted the possible locations of the difficult target. Within each trial, "difficult colour" rings were all presented on one side of fixation, and "easy colour" rings were all presented on the other side of fixation. As a result, the set size for a given difficulty varied as the proportion of red to blue rings varied. If red is associated with the easy judgement, then on trials with one red and 7 blue rings, participants could benefit from directing attention to the easy target immediately and responding. On the other hand, if there were seven red rings and only one blue, participants would have to decide whether to allocate their attention immediately to the difficult rectangle and attempt a judgment, or whether they would prefer to search through the seven red rings to find the easy rectangle and make their judgement.



## Stimuli

## Experimental procedure

## EEG recording

## EEG Processing

## Statistical analysis

# Results

## Behavioural results
```{r organiseBehavData}
behavData <- read.table("Behaviour/BehavData.csv",header = TRUE, sep=",")

#Remove lots of the default EPrime columns
behavData <- select(behavData,-c(ExperimentName	,Session	,Clock.Information	,DataFile.Basename	,Display.RefreshRate	,ExperimentVersion	,PracAcc	,PracRT	,RandomSeed	,RuntimeCapabilities	,RuntimeVersion	,RuntimeVersionExpected	,SessionDate	,SessionStartDateTimeUtc	,SessionTime	,StudioVersion	,totalEuro	,totalPoints	,FiveDiffLeftFar	,FiveDiffLeftNear	,FiveDiffRightFar	,FiveDiffRightNear	,FiveEasyLeftFar	,FiveEasyLeftNear	,FiveEasyRightFar	,FiveEasyRightNear	,FourDiffLeftFar	,FourDiffLeftNear	,FourDiffRightFar	,FourDiffRightNear	,FourEasyLeftFar	,FourEasyLeftNear	,FourEasyRightFar	,FourEasyRightNear	,image1x	,image1y	,image2x	,image2y	,image3x	,image3y	,image4x	,image4y	,image5x	,image5y	,image6x	,image6y	,image7x	,image7y	,image8x	,image8y	,leftImage1	,leftImage2	,leftImage3	,leftImage4	,leftImage5	,leftImage6	,leftImage7	,leftImage8	,OneDiffLeftFar	,OneDiffLeftNear	,OneDiffRightFar	,OneDiffRightNear	,OneEasyLeftFar	,OneEasyLeftNear	,OneEasyRightFar	,OneEasyRightNear	,Response.ACC	,Response.CRESP	,Response.DurationError	,Response.OnsetDelay	,Response.OnsetTime	,Response.OnsetToOnsetTime	,Response.RESP	,Response.RT	,Response.RTTime	,Response1.ACC	,Response1.CRESP	,Response1.DurationError	,Response1.OnsetDelay	,Response1.OnsetTime	,Response1.OnsetToOnsetTime	,Response1.RESP	,Response1.RT	,Response1.RTTime	,rightImage1	,rightImage2	,rightImage3	,rightImage4	,rightImage5	,rightImage6	,rightImage7	,rightImage8	,Search.DurationError	,Search.OffsetTime	,Search.OnsetDelay	,Search.OnsetTime	,SevenDiffLeftFar	,SevenDiffLeftNear	,SevenDiffRightFar	,SevenDiffRightNear	,SevenEasyLeftFar	,SevenEasyLeftNear	,SevenEasyRightFar	,SevenEasyRightNear	,SixDiffLeftFar	,SixDiffLeftNear	,SixDiffRightFar	,SixDiffRightNear	,SixEasyLeftFar	,SixEasyLeftNear	,SixEasyRightFar	,SixEasyRightNear	,ThreeDiffLeftFar	,ThreeDiffLeftNear	,ThreeDiffRightFar	,ThreeDiffRightNear	,ThreeEasyLeftFar	,ThreeEasyLeftNear	,ThreeEasyRightFar	,ThreeEasyRightNear	,TwoDiffLeftFar	,TwoDiffLeftNear	,TwoDiffRightFar	,TwoDiffRightNear	,TwoEasyLeftFar	,TwoEasyLeftNear	,TwoEasyRightFar	,TwoEasyRightNear	)
       )
#Remove practice trials
behavData <- filter(behavData, Running.Block. != "Practice")

#Make subejct a factor
behavData$Subject <- as.factor(behavData$Subject)

#Reorder the relevant variable factors and make table
behavData$collapseNFLR <- factor(behavData$collapseNFLR, levels = c("One", "Two", "Three", "Four", "Five", "Six", "Seven"))

```

(ref:indvSubjChoice) The proportion of trials where participants chose to respond to the easy target as a function of set size for the easy target. Greater than 50% would indicate a preference for the easy target in that condition, whereas less than 50% would indicate a preference for the difficult target in that condition.

```{r plotIndvSubjChoice, fig.cap="(ref:indvSubjChoice)"}
#Make group RT
groupChoice <- behavData %>%
  mutate(Subject = "Average") %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(numEasy = sum(ChoseEasy), numDiff = sum(ChoseDiff)) %>%
  mutate(totalTrials = numEasy+numDiff) %>%
  mutate(propEasy = numEasy/totalTrials)
#Plot participant choices
behavData %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(numEasy = sum(ChoseEasy), numDiff = sum(ChoseDiff)) %>%
  mutate(totalTrials = numEasy+numDiff) %>%
  mutate(propEasy = numEasy/totalTrials) %>%
  ggplot(., aes(collapseNFLR,propEasy, colour = Subject, group = Subject)) +
  #geom_rect(aes(xmin = 0, xmax = Inf, ymin = 0.5, ymax = 1), fill = "deepskyblue1", alpha = 0.2, colour = NA) +
  #geom_rect(aes(xmin = 0, xmax = Inf, ymin = 0, ymax = .5), fill = "tomato1", colour = NA) +
  geom_line(alpha = 0.5, size = 1) +
  geom_point(data = groupChoice, size = 3.5, color = "black") + 
  geom_line(data = groupChoice, size = 2.5, color = "black") +
  geom_hline(yintercept = 0.5) +
  scale_x_discrete(name ="Number of easy-coloured objects") +
  scale_y_continuous(limits = c(0,1),name ="Proportion of easy target selections", breaks = seq(0, 1, .25)) +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()+
  theme(axis.line = element_line(color = "black", 
                           size = 1, linetype = "solid"))
stats <- behavData %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(numEasy = sum(ChoseEasy), numDiff = sum(ChoseDiff)) %>%
  mutate(totalTrials = numEasy+numDiff) %>%
  mutate(propEasy = numEasy/totalTrials)
contrasts(stats$collapseNFLR) <- contr.poly(7)
result <- lm(propEasy ~ 1 + collapseNFLR, data = stats)
round(summary(result)$coefficients,3)
```

(ref:indvSubjAcc) Participant accuracy as a function of easy target set size.

```{r plotIndvSubjAccuracy, fig.cap="(ref:indvSubjAcc)"}
#Make group acc
groupAcc <- behavData %>%
  mutate(Subject = "Average", Search.ACC = Search.ACC*100) %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(Accuracy = mean(Search.ACC))
behavData %>%
  mutate(Search.ACC = Search.ACC*100) %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(Accuracy = mean(Search.ACC)) %>%
  ggplot(., aes(collapseNFLR,Accuracy, colour = Subject, group = Subject)) +
  geom_line(alpha = 0.5) + 
  geom_point(data = groupAcc, size = 2.5, color = "black") +
  geom_line(data = groupAcc, size = 1.5, color = "black") +
  scale_x_discrete(name ="Number of easy-coloured objects") +
  scale_y_continuous(name ="Accuracy (%)", limits = c(50,100)) +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()
stats <- behavData %>%
  mutate(Search.ACC = Search.ACC*100) %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(Accuracy = mean(Search.ACC))
contrasts(stats$collapseNFLR) <- contr.poly(7)
result <- lm(Accuracy ~ 1 + collapseNFLR, data = stats)
round(summary(result)$coefficients,3)
```

(ref:indvSubjRT) Participants response time as a function of set size for the easy target.

```{r plotIndvSubjRT, fig.cap="(ref:indvSubjRT)"}
#Make group RT
groupRT <- behavData %>%
  filter(Search.ACC == 1) %>%
  mutate(Subject = "Average") %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(RT = mean(Search.RT)) %>%
  mutate(RT= ifelse(RT==0,NA,RT))
behavData %>%
  filter(Search.ACC == 1) %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(RT = mean(Search.RT)) %>%
  mutate(RT= ifelse(RT==0,NA,RT)) %>%
  ggplot(., aes(collapseNFLR,RT, colour = Subject, group = Subject)) +
  geom_line(alpha = 0.5) +
  geom_point(data = groupRT, size = 2.5, color = "black") +
  geom_line(data = groupRT, size = 1.5, color = "black") +
  scale_x_discrete(name ="Number of easy-coloured objects") +
  scale_y_continuous(name ="Response time (ms)", limits = c(500,1000)) +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()
stats <- behavData %>%
  filter(Search.ACC == 1) %>%
  group_by(collapseNFLR,Subject) %>%
  summarise(RT = mean(Search.RT)) %>%
  mutate(RT= ifelse(RT==0,NA,RT))
contrasts(stats$collapseNFLR) <- contr.poly(7)
result <- lm(RT ~ 1 + collapseNFLR, data = stats)
round(summary(result)$coefficients,3)
```

## ERP results

```{r organiseERPData}
dPath = 'EEG/Visuals/'
fPrefix = 'N2pc'

#####
#Creates aggregate of all participant data (needs dPath and fPrefix)
eFilePattern = paste(fPrefix,"*_epochs.csv", sep="")
lFilePattern = paste(fPrefix,"*_LH.csv", sep="")
rFilePattern = paste(fPrefix,"*_RH.csv", sep="")
eFileList = list.files(dPath, pattern=glob2rx(eFilePattern))
lFileList = list.files(dPath, pattern=glob2rx(lFilePattern))
rFileList = list.files(dPath, pattern=glob2rx(rFilePattern))

#create variables using first dataset
epochInfo = read.csv(file = paste(dPath,eFileList[1], sep=""))
epochInfo$Subject = 1
lHemData = read.csv(file = paste(dPath,lFileList[1], sep=""), header = FALSE)
rHemData = read.csv(file = paste(dPath,rFileList[1], sep=""), header = FALSE)
#append the other datasets to the above variables
for (subj in 2:length(eFileList)) {
  curEpochInfo = read.csv(file = paste(dPath,eFileList[subj], sep=""))
  curEpochInfo$Subject = subj
  curLHemData = read.csv(file = paste(dPath,lFileList[subj], sep=""), header = FALSE)
  curRHemData = read.csv(file = paste(dPath,rFileList[subj], sep=""), header = FALSE)
  
  epochInfo = rbind(epochInfo, curEpochInfo)
  lHemData = rbind(lHemData, curLHemData)
  rHemData = rbind(rHemData, curRHemData)
}

#clear stuff that I don't need
rm(curEpochInfo,curLHemData,curRHemData, fPrefix, eFileList, eFilePattern, lFileList, lFilePattern, rFileList, rFilePattern, subj)
#####
#Permutation can be done at this stage using epochInfo$Hemifield = sample(epochInfo$Hemifield, replace=FALSE)
#combine all the data together into one long table
gathercols = colnames(lHemData)
lHemData$Hem = "Left"
rHemData$Hem = "Right"
scalpData = rbind(lHemData,rHemData)
origEpochInfo = rbind(epochInfo,epochInfo)

allData <- cbind(origEpochInfo, scalpData)
allData <- gather(allData, "sample", "voltage", gathercols, factor_key = TRUE)

#Tidy variable names etc. and create any necessary variables - could use unite
allData$sample <- as.integer(substring(allData$sample,2))
allData <- allData %>% mutate(Hemisphere = ifelse(EasyField==Hem, "Ipsilateral", "Contralateral"))
allData$SimpSet <- allData$EasySet
allData$SimpSet <- recode(allData$SimpSet, "1" = "Small", "2" = "Small", "3" ="Medium", "4"="Medium", "5"="Medium", "6"="Large", "7"="Large")

#clear stuff that I don't need
rm(origEpochInfo,scalpData)
```

```{r setParams}
baseline = 200
srateMultiplier = 2
winSize = 50
winBnd <- 0.8
fixedWin=1


subjRej <- allData %>%
    filter(Event == "Search",sample == 1, Hemisphere == 'Contralateral') %>%
    group_by(Subject) %>%
    summarise(trialCount = sum(sample)) %>%
  mutate(rej = ifelse(trialCount < 600,1,0))
for (i in unique(allData$Subject)) {
  allData$rej[allData$Subject == i] = subjRej$rej[subjRej$Subject==i]
}
```

```{r grandAverageERP}
allData %>%
  filter(Event == "Search" & rej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(sample,Hemisphere) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Hemisphere, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample, diff)) +
  geom_line() +
  scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(2, "lines"), text= element_text(size=12))
```

### N2pc

```{r N2pcStats}
grandAverage <- allData %>%
  filter(Event == "Search" & rej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 180, sample < 350) %>%
  group_by(sample,Hemisphere) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Hemisphere, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
if (fixedWin) {
  N2pcStart = grandAverage$sample[grandAverage$diff == min(grandAverage$diff)]-winSize/2
  N2pcEnd = grandAverage$sample[grandAverage$diff == min(grandAverage$diff)]+winSize/2
} else {
  peakTime <- grandAverage$sample[grandAverage$diff == min(grandAverage$diff)]
  peakValue <- min(grandAverage$diff)
  N2pcStart <- grandAverage$sample[max(which(grandAverage[1:which(grandAverage$sample==peakTime)-1,]$diff>peakValue*winBnd))]
  postPeakData <- grandAverage[which(grandAverage$sample==peakTime)+1:nrow(grandAverage),]
  N2pcEnd <- postPeakData$sample[min(which(postPeakData$diff > peakValue*winBnd))]
}
N2pc.data <- allData %>%
  mutate(sample = sample*2-baseline) %>%
  filter(Event == "Search" & sample>N2pcStart & sample < N2pcEnd, rej == 0) %>%
  group_by(EasySet,Hemisphere,Subject) %>%
  summarise(mV = mean(voltage)) %>%
  spread(Hemisphere,mV) %>%
  mutate(diff = Contralateral - Ipsilateral)
#plot values
groupN2pc <- N2pc.data %>%
  mutate(Subject = "Average") %>%
  group_by(EasySet, Subject) %>%
  summarise(diff = mean(diff))
ggplot(N2pc.data, aes(x = EasySet, y = diff, colour = Subject, group = Subject)) +
  geom_line(alpha = 0.5, size = 1) +
  geom_point(data = groupN2pc, size = 3.5, color = "black") + 
  geom_line(data = groupN2pc, size = 2.5, color = "black") +
  scale_x_discrete(name ="Easy set-size") +
  scale_y_continuous(name ="N2pc Amplitude") +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()+
  theme(axis.line = element_line(color = "black", 
                           size = 1, linetype = "solid"))
N2pc.data %>%
  group_by(EasySet) %>%
  summarise(diff = mean(diff)) %>%
  ggplot(., aes(x = EasySet, y = diff)) +
  geom_point()
ggplot(N2pc.data, aes(x = EasySet, y = diff)) +
  geom_point()
N2pc.data$EasySet <- as.factor(N2pc.data$EasySet)
contrasts(N2pc.data$EasySet) <- contr.poly(7)
result <- lm(diff ~ 1 + EasySet, data = N2pc.data)
round(summary(result)$coefficients,3)
```

### P1pc

```{r P1pcStats}
grandAverage <- allData %>%
  filter(Event == "Search" & rej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 0, sample < 200) %>%
  group_by(sample,Hemisphere) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Hemisphere, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
if (fixedWin) {
  P1pcStart = grandAverage$sample[grandAverage$diff == max(grandAverage$diff)]-winSize/2
  P1pcEnd = grandAverage$sample[grandAverage$diff == max(grandAverage$diff)]+winSize/2
} else {
  peakTime <- grandAverage$sample[grandAverage$diff == min(grandAverage$diff)]
  peakValue <- min(grandAverage$diff)
  P1pcStart <- grandAverage$sample[max(which(grandAverage[1:which(grandAverage$sample==peakTime)-1,]$diff>peakValue*winBnd))]
  postPeakData <- grandAverage[which(grandAverage$sample==peakTime)+1:nrow(grandAverage),]
  P1pcEnd <- postPeakData$sample[min(which(postPeakData$diff > peakValue*winBnd))]
}
P1pc.data <- allData %>%
  mutate(sample = sample*2-baseline) %>%
  filter(Event == "Search" & sample>P1pcStart & sample < P1pcEnd, rej == 0) %>%
  group_by(EasySet,Hemisphere,Subject) %>%
  summarise(mV = mean(voltage)) %>%
  spread(Hemisphere,mV) %>%
  mutate(diff = Contralateral - Ipsilateral)
#plot values
groupP1pc <- P1pc.data %>%
  mutate(Subject = "Average") %>%
  group_by(EasySet, Subject) %>%
  summarise(diff = mean(diff))
ggplot(P1pc.data, aes(x = EasySet, y = diff, colour = Subject, group = Subject)) +
  geom_line(alpha = 0.5, size = 1) +
  geom_point(data = groupP1pc, size = 3.5, color = "black") + 
  geom_line(data = groupP1pc, size = 2.5, color = "black") +
  scale_x_discrete(name ="Easy set-size") +
  scale_y_continuous(name ="P1pc Amplitude") +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()+
  theme(axis.line = element_line(color = "black", 
                           size = 1, linetype = "solid"))
P1pc.data %>%
  group_by(EasySet) %>%
  summarise(diff = mean(diff)) %>%
  ggplot(., aes(x = EasySet, y = diff)) +
  geom_point()
ggplot(P1pc.data, aes(x = EasySet, y = diff)) +
  geom_point()
P1pc.data$EasySet <- as.factor(P1pc.data$EasySet)
contrasts(P1pc.data$EasySet) <- contr.poly(7)
result <- lm(diff ~ 1 + EasySet, data = P1pc.data)
round(summary(result)$coefficients,3)
```

### SPCN

```{r SPCNStats}
SPCNStart = 300
SPCNEnd = 600

SPCN.data <- allData %>%
  mutate(sample = sample*2-baseline) %>%
  filter(Event == "Search" & sample>SPCNStart & sample < SPCNEnd, rej == 0) %>%
  group_by(EasySet,Hemisphere,Subject) %>%
  summarise(mV = mean(voltage)) %>%
  spread(Hemisphere,mV) %>%
  mutate(diff = Contralateral - Ipsilateral)
#plot values
groupSPCN <- SPCN.data %>%
  mutate(Subject = "Average") %>%
  group_by(EasySet, Subject) %>%
  summarise(diff = mean(diff))
ggplot(SPCN.data, aes(x = EasySet, y = diff, colour = Subject, group = Subject)) +
  geom_line(alpha = 0.5, size = 1) +
  geom_point(data = groupSPCN, size = 3.5, color = "black") + 
  geom_line(data = groupSPCN, size = 2.5, color = "black") +
  scale_x_discrete(name ="Easy set-size") +
  scale_y_continuous(name ="SPCN Amplitude") +
  guides(colour=FALSE, group = FALSE) +
  theme_apa()+
  theme(axis.line = element_line(color = "black", 
                           size = 1, linetype = "solid"))
SPCN.data %>%
  group_by(EasySet) %>%
  summarise(diff = mean(diff)) %>%
  ggplot(., aes(x = EasySet, y = diff)) +
  geom_point()
ggplot(SPCN.data, aes(x = EasySet, y = diff)) +
  geom_point()
SPCN.data$EasySet <- as.factor(SPCN.data$EasySet)
contrasts(SPCN.data$EasySet) <- contr.poly(7)
result <- lm(diff ~ 1 + EasySet, data = SPCN.data)
round(summary(result)$coefficients,3)
```

(ref:fullSetERPCap) Subtractracted ERPs showing the lateralized response contralateral to the side of the easy target as a function of easy set size. Component windows are highlighted.


```{r fullSetPlot, fig.cap="(ref:fullSetERPCap)"}
my_palette <- brewer.pal(name="Blues",n=9)[3:9]
#Subtracted ERPs split by all set sizes
allData %>%
  filter(Event == "Search", rej == 0) %>%
  mutate(sample = sample*2-baseline, EasySet = as.factor(EasySet)) %>%
  group_by(EasySet,sample,Hemisphere) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Hemisphere, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(xmin = P1pcStart, xmax = P1pcEnd, ymin = -Inf, ymax = 0, fill = "lemonchiffon") +
    geom_rect(xmin = N2pcStart, xmax = N2pcEnd, ymin = Inf, ymax = 0, fill = "lemonchiffon") +
    geom_rect(xmin = SPCNStart, xmax = SPCNEnd, ymin = Inf, ymax = 0, fill = "lemonchiffon") +
    geom_line(aes(colour = EasySet),size=1) +
    scale_color_manual(values = my_palette) +
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(2, "lines"), text= element_text(size=12))
```

# Discussion

\newpage

```{r create_r-references}
r_refs(file = "NP32019_references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
